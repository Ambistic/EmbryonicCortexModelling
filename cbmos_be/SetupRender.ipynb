{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ete3 import Tree, NodeStyle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path as P\n",
    "from collections import defaultdict, Counter\n",
    "from debug import debugger, saver, loader\n",
    "from scipy import stats\n",
    "from matplotlib import cm\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../output/results/expLI_cbmos2021/\"\n",
    "ROOT_EXPORT = \"../output/results/expLI_cbmos2021/export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(ROOT_EXPORT).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_param_from_name(name):\n",
    "    name = \"_\".join(name.split(\"_\")[1:])\n",
    "    name = \".\".join(name.split(\".\")[:-1])\n",
    "    shorten = name\n",
    "    # shorten = name.replace(\"__\", \"_\")\n",
    "    \n",
    "    exp, model, *param, value, n = shorten.split(\"_\")\n",
    "    param = \"_\".join(param)\n",
    "    return dict(exp=exp, model=model, param=param, value=value, n=n, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dir(root):\n",
    "    all_params = list()\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file.startswith(\"stats_\"):\n",
    "                all_params.append(extract_param_from_name(file))\n",
    "                \n",
    "    return all_params\n",
    "params = read_dir(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_groups(params):\n",
    "    groups = defaultdict(list)\n",
    "    for param in params:\n",
    "        key = tuple((k, v) for k, v in param.items() if k in [\"exp\", \"model\", \"param\", \"value\"])\n",
    "        groups[key].append(param)\n",
    "    return groups\n",
    "\n",
    "def gather_metagroups(groups):\n",
    "    metagroups = defaultdict(dict)\n",
    "    controls = {listtuple_to_dict(key_group)[\"model\"]: value_group for key_group, value_group in groups.items()\n",
    "               if listtuple_to_dict(key_group)[\"param\"] == \"\"}\n",
    "    exp = {key_group: value_group for key_group, value_group in groups.items()\n",
    "               if listtuple_to_dict(key_group)[\"param\"] != \"\"}\n",
    "    \n",
    "    for key_group, value_group in exp.items():            \n",
    "        key_meta = tuple((k, v) for k, v in key_group if k in [\"exp\", \"model\", \"param\"])\n",
    "        value = {k: v for k, v in key_group}[\"value\"]\n",
    "        metagroups[key_meta][value] = value_group\n",
    "        \n",
    "    for key_meta in metagroups:\n",
    "        model = listtuple_to_dict(key_meta)[\"model\"]\n",
    "        param = listtuple_to_dict(key_meta)[\"param\"]\n",
    "        defval = str(get_default_val(param))\n",
    "        \n",
    "        metagroups[key_meta][defval] = controls[model]\n",
    "    \n",
    "    return metagroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = gather_groups(params)\n",
    "\n",
    "metagroups = gather_metagroups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderers = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_add(history, tree, cell_id):\n",
    "    if cell_id == -1:\n",
    "        return\n",
    "    cell = history.loc[cell_id]\n",
    "    node = tree.add_child(name=cell_id, dist=cell[\"Tc_h\"])\n",
    "    node.set_style(STYLE.get(cell[\"type\"]))\n",
    "    for child_id in cell[[\"child1\", \"child2\"]]:\n",
    "        recursive_add(history, node, child_id)\n",
    "\n",
    "def tree_from_cell(history, cell_id):\n",
    "    tree = Tree()\n",
    "    recursive_add(history, tree, cell_id)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS\n",
    "def preprocess_history(param):\n",
    "    file = \"history_\" + param[\"name\"] + \".csv\"\n",
    "    df = pd.read_csv(P(ROOT) / file, index_col=0)\n",
    "    df[\"index\"] = df[\"index\"].astype(int)\n",
    "    df[\"child1\"] = df[\"child1\"].fillna(-1)\n",
    "    df[\"child2\"] = df[\"child2\"].fillna(-1)\n",
    "    df[\"child1\"] = df[\"child1\"].astype(int)\n",
    "    df[\"child2\"] = df[\"child2\"].astype(int)\n",
    "    df.set_index(\"index\")\n",
    "    return df\n",
    "\n",
    "def preprocess_stats(param):\n",
    "    file = \"stats_\" + param[\"name\"] + \".csv\"\n",
    "    df = pd.read_csv(P(ROOT) / file)\n",
    "    return df\n",
    "        \n",
    "def preprocess_nb_progenitor(param):\n",
    "    stats = preprocess_stats(param)\n",
    "    ref = stats.whole_pop_size.iloc[0]\n",
    "    return dict(x=stats.time, y=stats.progenitor_pop_size / ref)\n",
    "\n",
    "def preprocess_nb_cells(param):\n",
    "    stats = preprocess_stats(param)\n",
    "    ref = stats.whole_pop_size.iloc[0]\n",
    "    return dict(x=stats.time, y=stats.whole_pop_size / ref)\n",
    "\n",
    "def preprocess_ratio(param):\n",
    "    stats = preprocess_stats(param)\n",
    "    stats = stats.fillna(0)\n",
    "    if \"size_type_Cycling\" in stats.columns:\n",
    "        non_IP = stats.size_type_Cycling\n",
    "        IP = 0\n",
    "    else:\n",
    "        non_IP = stats.size_type_RG + stats.size_type_GP if \"size_type_GP\" in stats.columns else stats.size_type_RG\n",
    "        IP = stats.size_type_IP\n",
    "    \n",
    "    return dict(x=stats.time, y=IP / (non_IP + IP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_progeny(param):\n",
    "    history = preprocess_history(param)\n",
    "    return progeny_along_time(history)\n",
    "\n",
    "def preprocess_progeny_all(param):\n",
    "    history = preprocess_history(param)\n",
    "    return progeny_along_time(history, only_leaves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_progeny(history, cell_id, tree=None, only_leaves=True):\n",
    "    if tree is None:\n",
    "        tree = tree_from_cell(history, cell_id)\n",
    "    if only_leaves:\n",
    "        nodes = tree.get_leaves()\n",
    "    else:\n",
    "        nodes = list(filter(lambda x: isinstance(x.name, (int, np.integer)), tree.traverse()))\n",
    "        \n",
    "    return Counter(list(map(lambda x: history.loc[x.name][\"type\"], nodes)))\n",
    "\n",
    "def progeny_along_time(history, _type=\"RG\", only_leaves=True, step=2., appear_time=49.):\n",
    "    ret_df = pd.DataFrame()\n",
    "    \n",
    "    min_time, max_time = min(history[\"appear_time\"]), max(history[\"appear_time\"])\n",
    "    dict_trees = dict()\n",
    "    # build trees\n",
    "    for i, row in history.iterrows():\n",
    "        if row[\"appear_time\"] == appear_time:\n",
    "            tree = tree_from_cell(history, row[\"index\"])\n",
    "            dict_trees.update({x.name: x for x in tree.traverse()})\n",
    "    \n",
    "    for T in np.arange(min_time, max_time, step):\n",
    "        count_T = Counter()\n",
    "        df_T = history[(history[\"appear_time\"] >= T) &\n",
    "                  (history[\"appear_time\"] < (T + step)) & (history[\"type\"] == _type)]\n",
    "        N = len(df_T)\n",
    "        if not N:\n",
    "            continue\n",
    "            \n",
    "        for i, cell in df_T.iterrows():\n",
    "            progeny = count_total_progeny(history, cell[\"index\"], dict_trees.get(cell[\"index\"]), only_leaves=only_leaves)\n",
    "            count_T.update(progeny)\n",
    "            \n",
    "        new_row = {k: v / N for k, v in dict(count_T).items()}\n",
    "        new_row[\"time\"] = T\n",
    "        ret_df = ret_df.append(new_row, ignore_index=True)\n",
    "        \n",
    "    ret_df = ret_df.fillna(0.0)\n",
    "        \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.render(\"mytree.png\", w=183, units=\"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sum(line):\n",
    "    total = 0\n",
    "    for k in sorted(set(line.keys()) - {\"x\", \"label\"}):\n",
    "        plt.fill_between(line[\"x\"], total, total + line[k][\"mean\"], label=k)\n",
    "        total = total + line[k][\"mean\"]\n",
    "    plt.legend()\n",
    "\n",
    "def draw_line(x, y, label=None):\n",
    "    if isinstance(y, dict):\n",
    "        return draw_mean_sd_line(x, y[\"mean\"], y[\"sd\"], label=label)\n",
    "        \n",
    "    plt.plot(x, y, label=label)\n",
    "        \n",
    "def draw_mean_sd_line(x, mean, sd, label=None):\n",
    "    plt.plot(x, mean, label=label)\n",
    "    plt.fill_between(x, (mean-sd), (mean+sd), alpha=.3)\n",
    "\n",
    "def plot_lines(lines, title=None):\n",
    "    lines.sort(key=lambda x: x.get(\"label\", \"NO_LABEL\"))\n",
    "    plt.figure()\n",
    "    for line in lines:\n",
    "        draw_line(line[\"x\"], line[\"y\"], line.get(\"label\"))\n",
    "    plt.legend()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "def plot_sum(lines, title=None):\n",
    "    lines.sort(key=lambda x: x.get(\"label\", \"NO_LABEL\"))\n",
    "    if len(lines) > 6:\n",
    "        raise ValueError(\"Maximum allowed plot is 6\")\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    for i, line in enumerate(lines):\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        draw_sum(line)\n",
    "        plt.title(line.get(\"label\", \"NO_LABEL\"))\n",
    "    if title:\n",
    "        plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(lines, title=None):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    keys = set().union(*[element.keys() for element in lines]) - {\"label\"}\n",
    "    lines.sort(key=lambda x: x.get(\"label\", \"NO_LABEL\"))\n",
    "    labels = [element.get(\"label\", \"NO_LABEL\") for i, element in enumerate(lines)]\n",
    "    null = {\"mean\": 0, \"sd\": 0}\n",
    "    for i, k in enumerate(keys):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.title(k)\n",
    "        vec = [element.get(k, null).get(\"mean\") for element in lines]\n",
    "        err = [element.get(k, null).get(\"sd\") for element in lines]\n",
    "        plt.bar(labels, vec, yerr=err, color=cm.Set2.colors)\n",
    "        \n",
    "    if title:\n",
    "        plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sd(ls):\n",
    "    min_len = min([len(sample[\"x\"]) for sample in ls])\n",
    "    x = ls[0][\"x\"][:min_len]\n",
    "    mean = np.mean([sample[\"y\"][:min_len] for sample in ls], axis=0)\n",
    "    sd = np.std([sample[\"y\"][:min_len] for sample in ls], axis=0)\n",
    "    return {\"x\": x, \"y\":{\"mean\": mean, \"sd\": sd}}\n",
    "\n",
    "def mean_progeny(ls):\n",
    "    \"\"\"Runs on all columns\"\"\"\n",
    "    min_len = min([len(sample[\"time\"]) for sample in ls])\n",
    "    dict_res = dict(x=ls[0][\"time\"][:min_len])\n",
    "    \n",
    "    col = {colname for sample in ls for colname in sample.columns} - {\"time\"}\n",
    "\n",
    "    for c in col:\n",
    "        mean = np.mean([sample.get(c, [0] * min_len)[:min_len] for sample in ls], axis=0)\n",
    "        sd = np.std([sample.get(c, [0] * min_len)[:min_len] for sample in ls], axis=0)\n",
    "        dict_res[c] = {\"mean\": mean, \"sd\": sd}\n",
    "    return dict_res\n",
    "\n",
    "def mean_dict(ls):\n",
    "    dict_res = dict()\n",
    "    keys = set().union(*[element.keys() for element in ls])\n",
    "    for k in keys:\n",
    "        vec = [element[k] for element in ls if k in element]\n",
    "        dict_res[k] = {\"mean\": np.mean(vec), \"sd\": np.std(vec)}\n",
    "        \n",
    "    return dict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_parents(df):\n",
    "    tmp_df = pd.merge(df, df, how='inner', left_on=\"child1\", right_on=\"index\", suffixes=('_M', '_D1'))\n",
    "    full_df = pd.merge(tmp_df, df.rename(columns=lambda x: x + \"_D2\"), how='inner', left_on=\"child2_M\",\n",
    "                       right_on=\"index_D2\", suffixes=('_M', '_D2'))\n",
    "    full_df[\"group\"] = 2 + 1 * (full_df[\"appear_time_M\"] > 75)\n",
    "    full_df\n",
    "    return full_df\n",
    "\n",
    "def get_sub_df_merged(full_df, key1, key2, group):\n",
    "    no_gp = (full_df[\"type_D1\"] != \"GP\") & (full_df[\"type_D2\"] != \"GP\")\n",
    "    notnull = full_df[key1].notnull() & full_df[key2].notnull()\n",
    "    notzero = (full_df[key1] != 0.) & (full_df[key2] != 0.)\n",
    "    goodgroup = full_df[\"group\"].isin(group)\n",
    "    filt =  goodgroup & no_gp & notnull & notzero\n",
    "    cur_df = full_df.loc[filt, :]\n",
    "    return cur_df\n",
    "\n",
    "def metrics_tc_mother_daughter(full_df):\n",
    "    key1, key2 = \"Tc_h_M\", \"Tc_h_D1\"\n",
    "    cur_df = get_sub_df_merged(full_df, key1, key2, [2, 3])\n",
    "    var1 = cur_df[key1] / cur_df[key2]\n",
    "    var2 = cur_df[key1] - cur_df[key2]\n",
    "    return dict(\n",
    "        mean_ratio_m_d_g23=np.mean(var1), \n",
    "        std_ratio_m_d_g23=np.std(var1), \n",
    "        mean_diff_m_d_g23=np.mean(var2), \n",
    "        std_diff_m_d_g23=np.std(var2)\n",
    "    )\n",
    "\n",
    "def metrics_tc_daughters(full_df):\n",
    "    key1, key2 = \"Tc_h_D1\", \"Tc_h_D2\"\n",
    "    cur_df_g2 = get_sub_df_merged(full_df, key1, key2, [2])\n",
    "    cur_df_g3 = get_sub_df_merged(full_df, key1, key2, [3])\n",
    "    cur_df_g23 = get_sub_df_merged(full_df, key1, key2, [2, 3])\n",
    "    return dict(\n",
    "        corr_tc_daughter_g2=stats.pearsonr(cur_df_g2[key1], cur_df_g2[key2])[0],\n",
    "        corr_tc_daughter_g3=stats.pearsonr(cur_df_g3[key1], cur_df_g3[key2])[0],\n",
    "        corr_tc_daughter_g23=stats.pearsonr(cur_df_g23[key1], cur_df_g23[key2])[0],\n",
    "    )\n",
    "\n",
    "def corr_tc_output(full_df):\n",
    "    no_gp = (full_df[\"type_D1\"] != \"GP\") & (full_df[\"type_D2\"] != \"GP\")\n",
    "    prog_df = full_df[no_gp].copy()\n",
    "    prog_df[\"prog_D1\"] = prog_df[\"type_D1\"].apply(lambda x: \"Cycling\" if x in [\"IP\", \"RG\"] else \"PM\")\n",
    "    prog_df[\"prog_D2\"] = prog_df[\"type_D2\"].apply(lambda x: \"Cycling\" if x in [\"IP\", \"RG\"] else \"PM\")\n",
    "    prog_df[\"nb_child_pm\"] = (prog_df[\"prog_D1\"] == \"PM\").astype(int) + (prog_df[\"prog_D2\"] == \"PM\").astype(int)\n",
    "    prog_df_g2 = prog_df[prog_df[\"group\"].isin([2])]\n",
    "    prog_df_g3 = prog_df[prog_df[\"group\"].isin([3])]\n",
    "    prog_df_g23 = prog_df[prog_df[\"group\"].isin([2, 3])]\n",
    "    return dict(\n",
    "        corr_tc_output_g2=stats.pearsonr(prog_df_g2[\"nb_child_pm\"], prog_df_g2[\"Tc_h_M\"])[0],\n",
    "        corr_tc_output_g3=stats.pearsonr(prog_df_g3[\"nb_child_pm\"], prog_df_g3[\"Tc_h_M\"])[0],\n",
    "        corr_tc_output_g23=stats.pearsonr(prog_df_g23[\"nb_child_pm\"], prog_df_g23[\"Tc_h_M\"])[0],\n",
    "    )\n",
    "\n",
    "def fate_corr(full_df):\n",
    "    kC, kN = \"Cycling\", \"PM\"\n",
    "    prog_df = full_df.copy()\n",
    "    no_gp = (full_df[\"type_D1\"] != \"GP\") & (full_df[\"type_D2\"] != \"GP\")\n",
    "    filt = prog_df[\"group\"].isin([2, 3]) & no_gp\n",
    "    prog_df = prog_df[filt]\n",
    "    prog_df[\"prog_D1\"] = prog_df[\"type_D1\"].apply(lambda x: kC if x in [\"IP\", \"RG\"] else kN)\n",
    "    prog_df[\"prog_D2\"] = prog_df[\"type_D2\"].apply(lambda x: kC if x in [\"IP\", \"RG\"] else kN)\n",
    "    res_fate_cor = prog_df.groupby([\"prog_D1\", \"prog_D2\"]).size()\n",
    "    \n",
    "    CC, CN, NN = res_fate_cor[kC][kC], res_fate_cor[kC][kN] + res_fate_cor[kN][kC], res_fate_cor[kN][kN]\n",
    "    T = CC + CN + NN\n",
    "    pCC, pCN, pNN = CC / T, CN / T, NN / T\n",
    "    all_C, all_N = 2 * CC + CN, 2 * NN + CN\n",
    "    pC, pN = all_C / (T * 2), all_N / (T * 2)\n",
    "    eCC, eCN, eNN = pC**2, 2*pC*pN, pN**2\n",
    "    F_metric = 1 - pCN / eCN\n",
    "    return dict(\n",
    "        F_metric=F_metric,\n",
    "    )\n",
    "\n",
    "def preprocess_corr_metrics(param):\n",
    "    history = preprocess_history(param)\n",
    "    merged = merge_parents(history)\n",
    "    res = dict(\n",
    "        **metrics_tc_mother_daughter(merged),\n",
    "        **metrics_tc_daughters(merged),\n",
    "        **corr_tc_output(merged),\n",
    "        **fate_corr(merged)\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RendererPlot:\n",
    "    def __init__(self, name, preprocess_func, mean_func, plot_func):\n",
    "        self.name = name\n",
    "        self.preprocess_func = preprocess_func\n",
    "        self.mean_func = mean_func\n",
    "        self.plot_func = plot_func\n",
    "        \n",
    "    def __call__(self, metagroup, title=None):\n",
    "        lines = list()\n",
    "        for group_value, group in metagroup.items():\n",
    "            ls = []\n",
    "            for sample in group:\n",
    "                ls.append(self.preprocess_func(sample))\n",
    "            line = self.mean_func(ls)\n",
    "            line[\"label\"] = group_value\n",
    "            lines.append(line)\n",
    "        self.plot_func(lines, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_nb_progenitor = RendererPlot(\"nb_progenitor\", preprocess_nb_progenitor, mean_sd, plot_lines)\n",
    "render_nb_cells = RendererPlot(\"nb_cells\", preprocess_nb_cells, mean_sd, plot_lines)\n",
    "render_ratio = RendererPlot(\"ratioIP\", preprocess_ratio, mean_sd, plot_lines)\n",
    "render_progeny = RendererPlot(\"progeny leaves\", preprocess_progeny, mean_progeny, plot_sum)\n",
    "render_progeny_all = RendererPlot(\"progeny all\", preprocess_progeny_all, mean_progeny, plot_sum)\n",
    "render_corr_metrics = RendererPlot(\"corr_metrics\", preprocess_corr_metrics, mean_dict, plot_metrics)\n",
    "# render_neighborhood = RendererPlot(preprocess_neighborhood, mean_dict, plot_metrics)\n",
    "\n",
    "renderers = [render_nb_progenitor, render_nb_cells, render_ratio,\n",
    "            render_progeny, render_progeny_all, render_corr_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_name(key):\n",
    "    return [x[1] for x in key if x[0] == \"param\"][0].strip(\"_\")\n",
    "\n",
    "def get_name_for_file(key):\n",
    "    return \"_\".join([x[1].strip(\"_\") for x in key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expLI_tristateLI_bias_ratio_3'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name_for_file(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [04:33<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, meta in tqdm(metagroups.items()):\n",
    "    for renderer in renderers:\n",
    "        title = \" \".join([listtuple_to_dict(key).get(\"model\"), get_param_name(key), renderer.name])\n",
    "        renderer(meta, title=title)\n",
    "        plt.savefig(P(ROOT_EXPORT) / (get_name_for_file(key) + \"_\" + renderer.name + \".png\"))\n",
    "        plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "82\n",
      "101\n",
      "121\n",
      "149\n",
      "170\n",
      "183\n",
      "231\n",
      "249\n",
      "246\n",
      "226\n",
      "233\n",
      "217\n",
      "237\n",
      "201\n",
      "195\n",
      "164\n",
      "190\n",
      "157\n",
      "175\n",
      "34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cycling</th>\n",
       "      <th>PostMitotic</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>74.564706</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>48.585366</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.514851</td>\n",
       "      <td>31.039604</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.231405</td>\n",
       "      <td>23.008264</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026846</td>\n",
       "      <td>17.348993</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>15.111765</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.612022</td>\n",
       "      <td>11.628415</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>9.251082</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.481928</td>\n",
       "      <td>7.493976</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.556911</td>\n",
       "      <td>7.426829</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.455752</td>\n",
       "      <td>6.247788</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.613734</td>\n",
       "      <td>6.107296</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.562212</td>\n",
       "      <td>5.276498</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.654008</td>\n",
       "      <td>4.789030</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>4.263682</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.743590</td>\n",
       "      <td>3.671795</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.939024</td>\n",
       "      <td>3.085366</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.889474</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.993631</td>\n",
       "      <td>1.229299</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cycling  PostMitotic  time\n",
       "0   3.800000    74.564706  49.0\n",
       "1   2.500000    48.585366  51.0\n",
       "2   1.514851    31.039604  53.0\n",
       "3   1.231405    23.008264  55.0\n",
       "4   1.026846    17.348993  57.0\n",
       "5   0.870588    15.111765  59.0\n",
       "6   0.612022    11.628415  61.0\n",
       "7   0.575758     9.251082  63.0\n",
       "8   0.481928     7.493976  65.0\n",
       "9   0.556911     7.426829  67.0\n",
       "10  0.455752     6.247788  69.0\n",
       "11  0.613734     6.107296  71.0\n",
       "12  0.562212     5.276498  73.0\n",
       "13  0.654008     4.789030  75.0\n",
       "14  0.641791     4.263682  77.0\n",
       "15  0.743590     3.671795  79.0\n",
       "16  0.939024     3.085366  81.0\n",
       "17  0.889474     2.157895  83.0\n",
       "18  0.993631     1.229299  85.0\n",
       "19  1.000000     0.262857  87.0\n",
       "20  1.000000     0.000000  89.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@loader\n",
    "def progeny_along_time(history, _type=\"RG\", only_leaves=True, step=2., appear_time=49.):\n",
    "    ret_df = pd.DataFrame()\n",
    "    \n",
    "    min_time, max_time = min(history[\"appear_time\"]), max(history[\"appear_time\"])\n",
    "    dict_trees = dict()\n",
    "    # build trees\n",
    "    for i, row in history.iterrows():\n",
    "        if row[\"appear_time\"] == appear_time:\n",
    "            tree = tree_from_cell(history, row[\"index\"])\n",
    "            dict_trees.update({x.name: x for x in tree.traverse()})\n",
    "    \n",
    "    if _type not in history[\"type\"]:\n",
    "        _type = \"Cycling\"\n",
    "    \n",
    "    for T in np.arange(min_time, max_time, step):\n",
    "        count_T = Counter()\n",
    "        df_T = history[(history[\"appear_time\"] >= T) &\n",
    "                  (history[\"appear_time\"] < (T + step)) & (history[\"type\"] == _type)]\n",
    "        N = len(df_T)\n",
    "        print(N)\n",
    "        if not N:\n",
    "            continue\n",
    "        \n",
    "        for i, cell in df_T.iterrows():\n",
    "            progeny = count_total_progeny(history, cell[\"index\"], dict_trees.get(cell[\"index\"]), only_leaves=only_leaves)\n",
    "            count_T.update(progeny)\n",
    "            \n",
    "        new_row = {k: v / N for k, v in dict(count_T).items()}\n",
    "        new_row[\"time\"] = T\n",
    "        ret_df = ret_df.append(new_row, ignore_index=True)\n",
    "        \n",
    "    ret_df = ret_df.fillna(0.0)\n",
    "        \n",
    "    return ret_df\n",
    "\n",
    "progeny_along_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp': 'expLI', 'model': 'basic', 'param': '_diff_values_4', 'value': '0.480', 'n': 'n2', 'name': 'expLI_basic__diff_values_4_0.480_n2'}\n",
      "progeny_along_time inputs were saved at /home/nathan/other/thesis_nathan/EmbryonicCortexModelling/cbmos/.debug/progeny_along_time !\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-fd37f143e97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_progeny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "for i, (key, meta) in enumerate(metagroups.items()):\n",
    "    if i == 1:\n",
    "        for group_value, group in meta.items():\n",
    "            ls = []\n",
    "            for sample in group:\n",
    "                print(sample)\n",
    "                # file = \"history_\" + sample[\"name\"] + \".csv\"\n",
    "                # df = pd.read_csv(P(ROOT) / file, index_col=0)\n",
    "                x = preprocess_progeny(sample)\n",
    "                print(x)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], Empty DataFrame\n",
      "Columns: []\n",
      "Index: []]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/jupyterhub/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-d437e54f0bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmean_progeny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/other/thesis_nathan/EmbryonicCortexModelling/cbmos/debug.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not load the inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-266-d437e54f0bbe>\u001b[0m in \u001b[0;36mmean_progeny\u001b[0;34m(ls)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Runs on all columns\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmin_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdict_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-266-d437e54f0bbe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Runs on all columns\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmin_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdict_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "@loader\n",
    "def mean_progeny(ls):\n",
    "    \"\"\"Runs on all columns\"\"\"\n",
    "    print(ls)\n",
    "    min_len = min([len(sample[\"time\"]) for sample in ls])\n",
    "    dict_res = dict(x=ls[0][\"time\"][:min_len])\n",
    "    \n",
    "    col = {colname for sample in ls for colname in sample.columns} - {\"time\"}\n",
    "\n",
    "    for c in col:\n",
    "        mean = np.mean([sample.get(c, [0] * min_len)[:min_len] for sample in ls], axis=0)\n",
    "        sd = np.std([sample.get(c, [0] * min_len)[:min_len] for sample in ls], axis=0)\n",
    "        dict_res[c] = {\"mean\": mean, \"sd\": sd}\n",
    "    return dict_res\n",
    "\n",
    "mean_progeny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
